{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e5683e",
   "metadata": {},
   "source": [
    "# MMI 702 PROJECT - PART3 : SVM RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import glob\n",
    "import math\n",
    "from sklearn import svm\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b583a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read extracted features in part1 notebook\n",
    "features_1D_mfcc_13 = pd.read_pickle(\"./features/mfcc_13_features.pk1\")\n",
    "features_1D_mfcc_32 = pd.read_pickle(\"./features/mfcc_32_features.pk1\")\n",
    "features_1D_only_hnr = pd.read_pickle(\"./features/hnr_features.pk1\")\n",
    "features_1D_only_zcr = pd.read_pickle(\"./features/zcr_features.pk1\")\n",
    "\n",
    "#Examples for other features\n",
    "# features_1D_only_meanf0 = pd.read_pickle(\"./meanf0_features.pk1\")\n",
    "# features_1D_only_stdevf0 = pd.read_pickle(\"./stdevf0_features.pk1\")\n",
    "# features_1D_only_sc = pd.read_pickle(\"./sc_features.pk1\")\n",
    "# features_1D_only_localJitter = pd.read_pickle(\"./localJitter_features.pk1\")\n",
    "# features_1D_only_localShimmer = pd.read_pickle(\"./localShimmer_features.pk1\")\n",
    "\n",
    "features_1D_mfcc_copy_0 = pd.read_pickle(\"./features/mfcc_13_features.pk1\")\n",
    "features_1D_mfcc_copy_1 = pd.read_pickle(\"./features/mfcc_13_features.pk1\")\n",
    "\n",
    "features_1D_mfcc_32_copy_0 = pd.read_pickle(\"./features/mfcc_32_features.pk1\")\n",
    "features_1D_mfcc_32_copy_1 = pd.read_pickle(\"./features/mfcc_32_features.pk1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96926d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert features to desired form. Convert from pd.DataFrames to numpy arrays. \n",
    "# Also merge some features together. Variable names have documentation value.\n",
    "X_1D_mfcc_13 = np.array(features_1D_mfcc_13.feature.tolist())\n",
    "y_1D_mfcc_13 = np.array(features_1D_mfcc_13.class_label.tolist())\n",
    "\n",
    "X_1D_mfcc_32 = np.array(features_1D_mfcc_32.feature.tolist())\n",
    "y_1D_mfcc_32 = np.array(features_1D_mfcc_32.class_label.tolist())\n",
    "\n",
    "X_1D_mfcc_cpy_0 = np.array(features_1D_mfcc_copy_0.feature.tolist())\n",
    "X_1D_hnr_ = np.array(features_1D_only_hnr.feature.tolist())\n",
    "X_1D_zcr_ = np.array(features_1D_only_zcr.feature.tolist())\n",
    "X_1D_hnr_ = np.c_[X_1D_mfcc_cpy_0, X_1D_hnr_]\n",
    "X_1D_hnr_zcr_13 = np.c_[X_1D_hnr_,X_1D_zcr_]\n",
    "y_1D_hnr_zcr_13 = np.array(features_1D_only_hnr.class_label.tolist())\n",
    "\n",
    "X_1D_mfcc_32_cpy_0 = np.array(features_1D_mfcc_32_copy_0.feature.tolist())\n",
    "X_1D_hnr = np.array(features_1D_only_hnr.feature.tolist())\n",
    "X_1D_zcr = np.array(features_1D_only_zcr.feature.tolist())\n",
    "X_1D_hnr = np.c_[X_1D_mfcc_32_cpy_0, X_1D_hnr]\n",
    "X_1D_hnr_zcr_32 = np.c_[X_1D_hnr,X_1D_zcr]\n",
    "y_1D_hnr_zcr_32 = np.array(features_1D_only_hnr.class_label.tolist())\n",
    "\n",
    "print(\"Mfcc_13 shape:\", X_1D_mfcc_13.shape)\n",
    "print(\"Mfcc_32 shape:\", X_1D_mfcc_32.shape)\n",
    "print(\"Mfcc_13_hnr_zcr shape:\", X_1D_hnr_zcr_13.shape)\n",
    "print(\"Mfcc_32_hnr_zcr shape:\", X_1D_hnr_zcr_32.shape)\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ed614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read found best params for SVM in part2 notebook\n",
    "searchpara_mfcc_13 = joblib.load(\"./params/params_13_mfcc.pkl\")\n",
    "searchpara_mfcc_32 = joblib.load(\"./params/params_32_mfcc.pkl\")\n",
    "\n",
    "searchpara_mfcc_13_hnr_zcr = joblib.load(\"./params/params_13_mfcc_hnr_zcr.pkl\")\n",
    "searchpara_mfcc_32_hnr_zcr = joblib.load(\"./params/params_32_mfcc_hnr_zcr.pkl\")\n",
    "\n",
    "# searchpara_hnr = joblib.load(\"params_13_mfcc_hnr.pkl\")\n",
    "# searchpara_meanf0 = joblib.load(\"params_13_mfcc_meanf0.pkl\")\n",
    "# searchpara_stdevf0 = joblib.load(\"params_13_mfcc_hnr_stdevf0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct he SVM objects with loaded parameters\n",
    "SVM_mfcc_13 = svm.SVC(C=searchpara_mfcc_13.best_params_.get('C'), gamma=searchpara_mfcc_13.best_params_.get('gamma'))\n",
    "SVM_mfcc_32 = svm.SVC(C=searchpara_mfcc_32.best_params_.get('C'), gamma=searchpara_mfcc_32.best_params_.get('gamma'))\n",
    "\n",
    "SVM_mfcc_13_hnr_zcr = svm.SVC(C=searchpara_mfcc_13_hnr_zcr.best_params_.get('C'), gamma=searchpara_mfcc_13_hnr_zcr.best_params_.get('gamma'))\n",
    "SVM_mfcc_32_hnr_zcr = svm.SVC(C=searchpara_mfcc_32_hnr_zcr.best_params_.get('C'), gamma=searchpara_mfcc_32_hnr_zcr.best_params_.get('gamma'))\n",
    "\n",
    "# SVM_hnr = svm.SVC(C=searchpara_hnr.best_params_.get('C'), gamma=searchpara_hnr.best_params_.get('gamma'))\n",
    "# SVM_meanf0 = svm.SVC(C=searchpara_meanf0.best_params_.get('C'), gamma=searchpara_meanf0.best_params_.get('gamma'))\n",
    "# SVM_stdevf0 = svm.SVC(C=searchpara_stdevf0.best_params_.get('C'), gamma=searchpara_stdevf0.best_params_.get('gamma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate and display the performance results. \n",
    "#To get results, it performs training and testing. \n",
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    axes=None,\n",
    "    ylim=None,\n",
    "    cv=None,\n",
    "    n_jobs=None,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator instance\n",
    "        An estimator instance implementing `fit` and `predict` methods which\n",
    "        will be cloned for each validation.\n",
    "\n",
    "    title : str\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training vector, where ``n_samples`` is the number of samples and\n",
    "        ``n_features`` is the number of features.\n",
    "\n",
    "    y : array-like of shape (n_samples) or (n_samples, n_features)\n",
    "        Target relative to ``X`` for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array-like of shape (3,), default=None\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple of shape (2,), default=None\n",
    "        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, default=None\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like of shape (n_ticks,)\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the ``dtype`` is float, it is regarded\n",
    "        as a fraction of the maximum size of the training set (that is\n",
    "        determined by the selected validation method), i.e. it has to be within\n",
    "        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n",
    "        sets. Note that for classification the number of samples usually have\n",
    "        to be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "        return_times=True,\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, \"o-\")\n",
    "    axes[2].fill_between(\n",
    "        fit_times_mean,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display results\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "title = \"Learning Curves - 13_mfcc\"\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(\n",
    "    SVM_mfcc_13, title, X_1D_mfcc_13, y_1D_mfcc_13, axes=axes[:, 0], ylim=(0.7, 1.01), cv=cv, n_jobs=4\n",
    ")\n",
    "\n",
    "title1 = \"Learning Curves - 13_mfcc + hnr + zcr\"\n",
    "cv_1 = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(\n",
    "    SVM_mfcc_13_hnr_zcr, title1, X_1D_hnr_zcr_13, y_1D_hnr_zcr_13, axes=axes[:, 1], ylim=(0.7, 1.01), cv=cv_1, n_jobs=4\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c116a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display results\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "title2 = \"Learning Curves - 32_mfcc\"\n",
    "cv_2 = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(\n",
    "    SVM_mfcc_32, title2, X_1D_mfcc_32, y_1D_mfcc_32, axes=axes[:, 0], ylim=(0.7, 1.01), cv=cv, n_jobs=4\n",
    ")\n",
    "  \n",
    "\n",
    "title3 = \"Learning Curves - 32_mfcc + hnr + zcr\"\n",
    "cv_3 = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(\n",
    "    SVM_mfcc_32_hnr_zcr, title3, X_1D_hnr_zcr_32, y_1D_hnr_zcr_32, axes=axes[:, 1], ylim=(0.7, 1.01), cv=cv_1, n_jobs=4\n",
    ")\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
